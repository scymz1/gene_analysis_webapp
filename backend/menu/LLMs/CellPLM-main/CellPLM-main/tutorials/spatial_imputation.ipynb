{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56fc5a70",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aafcd9dc",
   "metadata": {},
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import hdf5plugin\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "from scipy.sparse import csr_matrix\n",
    "from CellPLM.utils import set_seed\n",
    "from CellPLM.utils.data import stratified_sample_genes_by_sparsity\n",
    "from CellPLM.pipeline.imputation import ImputationPipeline, ImputationDefaultPipelineConfig, ImputationDefaultModelConfig"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "536d3952",
   "metadata": {},
   "source": [
    "## Specify important parameters before getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "874f0469",
   "metadata": {},
   "source": [
    "DATASET = 'Liver' # 'Lung'\n",
    "PRETRAIN_VERSION = '20231027_85M'\n",
    "DEVICE = 'cuda:4'"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "044a88ad",
   "metadata": {},
   "source": [
    "## Load Downstream Dataset\n",
    "\n",
    "The example datasets here are taken from `HumanLungCancerPatient2` from [Lung cancer 2](https://info.vizgen.com/ffpe-showcase?submissionGuid=88ba0a44-26e2-47a2-8ee4-9118b9811fbf), `GSE131907_Lung` from [GSE131907](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE131907), `HumanLiverCancerPatient2` from [Liver cancer 2](https://info.vizgen.com/ffpe-showcase?submissionGuid=88ba0a44-26e2-47a2-8ee4-9118b9811fbf) and `GSE151530_Liver` from [GSE151530](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE151530).\n",
    "\n",
    "The data we released are already preprocessed, where we subset the SRT dataset by selecting the first 100 FOVs. For scRNA-seq datasets, we only preserve genes that are overlapped with the SRT dataset. This is to ensure that for all the genes involved in this example, we know the ground-truth gene expressions from the SRT dataset. Later, we will hold out part of the genes from the SRT dataset, and leverage information from the scRNA-seq dataset to impute them. Therefore, this gene filtering is only for the convenience of evaluation. In practice, we can leverage the scRNA-seq dataset to impute unmeasured genes in the SRT dataset.\n",
    "\n",
    "After the preprocessing, the AnnData object must contain following information:\n",
    "\n",
    "* `.obs['platform']` A string label for identification of SRT data. When platform is set to 'cosmx' or 'merfish', spatial positional information will be loaded.\n",
    "* `.obs['x_FOV_px']` For SRT data, please store the float/int type X coordinate of each cell here.\n",
    "* `.obs['y_FOV_px']` For SRT data, please store the float/int type Y coordinate of each cell here.\n",
    "* `.obs['batch']` For SRT data, batch refers to an FOV. For scRNA-seq data, batch refers to a sample. Please store a string type batch identifier here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c4d4d6",
   "metadata": {},
   "source": [
    "set_seed(11)\n",
    "if DATASET == 'Lung':\n",
    "    query_dataset = 'HumanLungCancerPatient2_filtered_ensg.h5ad'\n",
    "    ref_dataset = 'GSE131907_Lung_ensg.h5ad'\n",
    "    query_data = ad.read_h5ad(f'../data/{query_dataset}')\n",
    "    ref_data = ad.read_h5ad(f'../data/{ref_dataset}')\n",
    "\n",
    "elif DATASET == 'Liver':\n",
    "    query_dataset = 'HumanLiverCancerPatient2_filtered_ensg.h5ad'\n",
    "    ref_dataset = 'GSE151530_Liver_ensg.h5ad'\n",
    "    query_data = ad.read_h5ad(f'../data/{query_dataset}')\n",
    "    ref_data = ad.read_h5ad(f'../data/{ref_dataset}')\n",
    "\n",
    "target_genes = stratified_sample_genes_by_sparsity(query_data, seed=11) # This is for reproducing the hold-out gene lists in our paper\n",
    "query_data.obsm['truth'] = query_data[:, target_genes].X.toarray()\n",
    "query_data[:, target_genes].X = 0\n",
    "train_data = query_data.concatenate(ref_data, join='outer', batch_key=None, index_unique=None)\n",
    "\n",
    "train_data.obs['split'] = 'train'\n",
    "train_data.obs['split'][train_data.obs['batch']==query_data.obs['batch'][-1]] = 'valid'\n",
    "train_data.obs['split'][train_data.obs['batch']==ref_data.obs['batch'][-1]] = 'valid'"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f48b1058",
   "metadata": {},
   "source": [
    "## Specify gene to impute\n",
    "In the last step, we merge the query dataset (SRT) and the reference dataset (scRNA-seq). However, the query dataset does not measures all the genes. For fine-tuning the model, we need to specify which genes are measured in each dataset. Therefore, we create a dictionary for the imputation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd8a39a2",
   "metadata": {},
   "source": [
    "query_genes = [g for g in query_data.var.index if g not in target_genes]\n",
    "query_batches = list(query_data.obs['batch'].unique())\n",
    "ref_batches = list(ref_data.obs['batch'].unique())\n",
    "batch_gene_list = dict(zip(list(query_batches) + list(ref_batches),\n",
    "    [query_genes]*len(query_batches) + [ref_data.var.index.tolist()]*len(ref_batches)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ff96bc99",
   "metadata": {},
   "source": [
    "## Overwrite parts of the default config\n",
    "These hyperparameters are recommended for general purpose. We did not tune it for individual datasets. You may update them if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c6cccb6",
   "metadata": {},
   "source": [
    "pipeline_config = ImputationDefaultPipelineConfig.copy()\n",
    "model_config = ImputationDefaultModelConfig.copy()\n",
    "\n",
    "pipeline_config, model_config"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5dfe80a4",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd48872",
   "metadata": {},
   "source": [
    "Efficient data setup and fine-tuning can be seamlessly conducted using the CellPLM built-in `pipeline` module.\n",
    "\n",
    "First, initialize a `ImputationPipeline`. This pipeline will automatically load a pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e54b753e",
   "metadata": {},
   "source": [
    "pipeline = ImputationPipeline(pretrain_prefix=PRETRAIN_VERSION, # Specify the pretrain checkpoint to load\n",
    "                                      overwrite_config=model_config,  # This is for overwriting part of the pretrain config\n",
    "                                      pretrain_directory='../ckpt')\n",
    "pipeline.model"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "12d7d4a9",
   "metadata": {},
   "source": [
    "Next, employ the `fit` function to fine-tune the model on your downstream dataset. This dataset should be in the form of an AnnData object, where `.X` is a csr_matrix. See previous section for more details.\n",
    "\n",
    "Typically, a dataset containing approximately 20,000 cells can be trained in under 10 minutes using a V100 GPU card, with an expected GPU memory consumption of around 8GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b0b9cb",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "pipeline.fit(train_data, # An AnnData object\n",
    "            pipeline_config, # The config dictionary we created previously, optional\n",
    "            split_field = 'split', #  Specify a column in .obs that contains split information\n",
    "            train_split = 'train',\n",
    "            valid_split = 'valid',\n",
    "            batch_gene_list = batch_gene_list, # Specify genes that are measured in each batch, see previous section for more details\n",
    "            device = DEVICE,\n",
    "            ) "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "172f80ee",
   "metadata": {},
   "source": [
    "## Inference and evaluation\n",
    "Once the pipeline has been fitted to the downstream datasets, performing inference or evaluation on new datasets can be easily accomplished using the built-in `predict` and `score` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99af1706",
   "metadata": {},
   "source": [
    "pipeline.predict(\n",
    "        query_data, # An AnnData object\n",
    "        pipeline_config, # The config dictionary we created previously, optional\n",
    "        device = DEVICE,\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f773fa50",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "pipeline.score(\n",
    "                query_data, # An AnnData object\n",
    "                evaluation_config = {'target_genes': target_genes}, # The config dictionary we created previously, optional\n",
    "                label_fields = ['truth'], # A field in .obsm that stores the ground-truth for evaluation\n",
    "                device = DEVICE,\n",
    ")  "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15daa63",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellplm",
   "language": "python",
   "name": "cellplm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
